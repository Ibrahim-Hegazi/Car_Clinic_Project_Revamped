name: Reddit Data Pipeline

permissions:
  contents: write

on:
  schedule:
    - cron: '0 19 * * *'
  workflow_dispatch:

jobs:
  run-pipeline:
    name: Run Reddit Scraper
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        persist-credentials: true

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Cache pip
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run Prefect flow
      run: |
        python run_pipeline.py 2>&1 | tee pipeline_output.log

    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-logs
        path: pipeline_output.log

    - name: Prepare latest raw CSV for upload
      if: always()
      run: |
        LATEST_FILE=$(ls -t data/raw/*.csv | head -n 1)
        echo "Latest file: $LATEST_FILE"
        mkdir -p temp_upload
        cp "$LATEST_FILE" temp_upload/
      shell: bash

    - name: Upload latest raw CSV only
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: reddit-latest-raw
        path: temp_upload/
        retention-days: 7

    - name: Commit and Push New Raw Data
      env:
        GIT_AUTHOR_NAME: github-actions
        GIT_AUTHOR_EMAIL: github-actions@github.com
        GIT_COMMITTER_NAME: github-actions
        GIT_COMMITTER_EMAIL: github-actions@github.com
        GH_PAT: ${{ secrets.GH_PAT }}
      run: |
        git config user.name "$GIT_AUTHOR_NAME"
        git config user.email "$GIT_AUTHOR_EMAIL"

        git pull origin ${{ github.ref_name }}
        git add data/raw/

        if git diff --cached --quiet; then
          echo "No changes in data/raw/ to commit."
        else
          git commit -m "Add today's raw Reddit CSV"
          git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }} HEAD:${{ github.ref_name }}
        fi

  run-cleaner:
    name: Run LLM Cleaner (Ollama)
    runs-on: ubuntu-latest
    needs: run-pipeline

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          sudo systemctl disable --now ollama || true
          ollama serve > /tmp/ollama.log 2>&1 &
          sleep 10

      - name: Pull Mistral model
        run: |
          ollama pull mistral

      - name: Ensure cleaned directory exists
        run: mkdir -p data/cleaned

      - name: Check Raw Data Directory Contents
        run: |
          echo "üìÇ Raw data contents:"
          ls -lh data/raw

      - name: Run Reddit Data Cleaner Flow
        run: |
          echo "üì¶ Running Reddit Cleaner..."
          git pull origin ${{ github.ref_name }}
          python python_scripts/reddit_data_cleaner/flow.py 2>&1 | tee cleaning_output.log

      - name: Upload Cleaned Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reddit-cleaning-logs
          path: cleaning_output.log

      - name: Commit and Push Cleaned Data
        env:
          GIT_AUTHOR_NAME: github-actions
          GIT_AUTHOR_EMAIL: github-actions@github.com
          GIT_COMMITTER_NAME: github-actions
          GIT_COMMITTER_EMAIL: github-actions@github.com
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          git config user.name "$GIT_AUTHOR_NAME"
          git config user.email "$GIT_AUTHOR_EMAIL"
          git pull origin ${{ github.ref_name }}
          
          echo "üîç Checking contents of cleaned directory..."
          ls -lh data/cleaned || echo "‚ùå No cleaned directory found"
          
          CLEANED_FILE="data/cleaned/Reddit_CarAdvice_Cleaned_$(date +'%Y-%m-%d').csv"
          if [ -f "$CLEANED_FILE" ]; then
            echo "‚úÖ Found cleaned file: $CLEANED_FILE"
            git add "$CLEANED_FILE"
          else
            echo "‚ö†Ô∏è Cleaned file not found: $CLEANED_FILE"
          fi
          
          if git diff --cached --quiet; then
            echo "üö´ No new cleaned data to commit."
          else
            git commit -m "‚úÖ Cleaned Reddit data with Ollama [$(date +'%Y-%m-%d %H:%M:%S')]"
            git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }} HEAD:${{ github.ref_name }}
          fi
